// Code generated by kafka-protocol-go. DO NOT EDIT.

// Copyright (c) 2023 Cisco and/or its affiliates. All rights reserved.
//
//	Licensed under the Apache License, Version 2.0 (the "License");
//	you may not use this file except in compliance with the License.
//	You may obtain a copy of the License at
//
//	     https://www.apache.org/licenses/LICENSE-2.0
//
//	Unless required by applicable law or agreed to in writing, software
//	distributed under the License is distributed on an "AS IS" BASIS,
//	WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
//	See the License for the specific language governing permissions and
//	limitations under the License.
package fetchabletopicresponse

import (
	"bytes"
	"strconv"
	"strings"

	"emperror.dev/errors"
	"github.com/cisco-open/libnasp/components/kafka-protocol-go/pkg/protocol/messages/fetch/response/fetchabletopicresponse/partitiondata"
	typesbytes "github.com/cisco-open/libnasp/components/kafka-protocol-go/pkg/protocol/types/bytes"
	"github.com/cisco-open/libnasp/components/kafka-protocol-go/pkg/protocol/types/fields"
	"github.com/cisco-open/libnasp/components/kafka-protocol-go/pkg/protocol/types/varint"
)

var partitionDataPartitionIndex = fields.Context{
	SpecName:                    "PartitionIndex",
	LowestSupportedVersion:      0,
	HighestSupportedVersion:     32767,
	LowestSupportedFlexVersion:  12,
	HighestSupportedFlexVersion: 32767,
}
var partitionDataErrorCode = fields.Context{
	SpecName:                    "ErrorCode",
	LowestSupportedVersion:      0,
	HighestSupportedVersion:     32767,
	LowestSupportedFlexVersion:  12,
	HighestSupportedFlexVersion: 32767,
}
var partitionDataHighWatermark = fields.Context{
	SpecName:                    "HighWatermark",
	LowestSupportedVersion:      0,
	HighestSupportedVersion:     32767,
	LowestSupportedFlexVersion:  12,
	HighestSupportedFlexVersion: 32767,
}
var partitionDataLastStableOffset = fields.Context{
	SpecName:                    "LastStableOffset",
	CustomDefaultValue:          int64(-1),
	LowestSupportedVersion:      4,
	HighestSupportedVersion:     32767,
	LowestSupportedFlexVersion:  12,
	HighestSupportedFlexVersion: 32767,
}
var partitionDataLogStartOffset = fields.Context{
	SpecName:                    "LogStartOffset",
	CustomDefaultValue:          int64(-1),
	LowestSupportedVersion:      5,
	HighestSupportedVersion:     32767,
	LowestSupportedFlexVersion:  12,
	HighestSupportedFlexVersion: 32767,
}
var partitionDataDivergingEpoch = fields.Context{
	SpecName:                      "DivergingEpoch",
	SpecTag:                       fields.Tag(0),
	LowestSupportedVersion:        12,
	HighestSupportedVersion:       32767,
	LowestSupportedFlexVersion:    12,
	HighestSupportedFlexVersion:   32767,
	LowestSupportedTaggedVersion:  12,
	HighestSupportedTaggedVersion: 32767,
}
var partitionDataCurrentLeader = fields.Context{
	SpecName:                      "CurrentLeader",
	SpecTag:                       fields.Tag(1),
	LowestSupportedVersion:        12,
	HighestSupportedVersion:       32767,
	LowestSupportedFlexVersion:    12,
	HighestSupportedFlexVersion:   32767,
	LowestSupportedTaggedVersion:  12,
	HighestSupportedTaggedVersion: 32767,
}
var partitionDataSnapshotId = fields.Context{
	SpecName:                      "SnapshotId",
	SpecTag:                       fields.Tag(2),
	LowestSupportedVersion:        12,
	HighestSupportedVersion:       32767,
	LowestSupportedFlexVersion:    12,
	HighestSupportedFlexVersion:   32767,
	LowestSupportedTaggedVersion:  12,
	HighestSupportedTaggedVersion: 32767,
}
var partitionDataAbortedTransactions = fields.Context{
	SpecName:                        "AbortedTransactions",
	LowestSupportedVersion:          4,
	HighestSupportedVersion:         32767,
	LowestSupportedFlexVersion:      12,
	HighestSupportedFlexVersion:     32767,
	LowestSupportedNullableVersion:  4,
	HighestSupportedNullableVersion: 32767,
}
var partitionDataPreferredReadReplica = fields.Context{
	SpecName:                    "PreferredReadReplica",
	CustomDefaultValue:          int32(-1),
	LowestSupportedVersion:      11,
	HighestSupportedVersion:     32767,
	LowestSupportedFlexVersion:  12,
	HighestSupportedFlexVersion: 32767,
}
var partitionDataRecords = fields.Context{
	SpecName:                        "Records",
	LowestSupportedVersion:          0,
	HighestSupportedVersion:         32767,
	LowestSupportedFlexVersion:      12,
	HighestSupportedFlexVersion:     32767,
	LowestSupportedNullableVersion:  0,
	HighestSupportedNullableVersion: 32767,
}

type PartitionData struct {
	unknownTaggedFields  []fields.RawTaggedField
	abortedTransactions  []partitiondata.AbortedTransaction
	records              fields.RecordBatches
	snapshotId           partitiondata.SnapshotId
	divergingEpoch       partitiondata.EpochEndOffset
	currentLeader        partitiondata.LeaderIdAndEpoch
	lastStableOffset     int64
	logStartOffset       int64
	highWatermark        int64
	partitionIndex       int32
	preferredReadReplica int32
	errorCode            int16
	isNil                bool
}

func (o *PartitionData) PartitionIndex() int32 {
	return o.partitionIndex
}

func (o *PartitionData) SetPartitionIndex(val int32) {
	o.isNil = false
	o.partitionIndex = val
}

func (o *PartitionData) ErrorCode() int16 {
	return o.errorCode
}

func (o *PartitionData) SetErrorCode(val int16) {
	o.isNil = false
	o.errorCode = val
}

func (o *PartitionData) HighWatermark() int64 {
	return o.highWatermark
}

func (o *PartitionData) SetHighWatermark(val int64) {
	o.isNil = false
	o.highWatermark = val
}

func (o *PartitionData) LastStableOffset() int64 {
	return o.lastStableOffset
}

func (o *PartitionData) SetLastStableOffset(val int64) {
	o.isNil = false
	o.lastStableOffset = val
}

func (o *PartitionData) LogStartOffset() int64 {
	return o.logStartOffset
}

func (o *PartitionData) SetLogStartOffset(val int64) {
	o.isNil = false
	o.logStartOffset = val
}

func (o *PartitionData) DivergingEpoch() partitiondata.EpochEndOffset {
	return o.divergingEpoch
}

func (o *PartitionData) SetDivergingEpoch(val partitiondata.EpochEndOffset) {
	o.isNil = false
	o.divergingEpoch = val
}

func (o *PartitionData) CurrentLeader() partitiondata.LeaderIdAndEpoch {
	return o.currentLeader
}

func (o *PartitionData) SetCurrentLeader(val partitiondata.LeaderIdAndEpoch) {
	o.isNil = false
	o.currentLeader = val
}

func (o *PartitionData) SnapshotId() partitiondata.SnapshotId {
	return o.snapshotId
}

func (o *PartitionData) SetSnapshotId(val partitiondata.SnapshotId) {
	o.isNil = false
	o.snapshotId = val
}

func (o *PartitionData) AbortedTransactions() []partitiondata.AbortedTransaction {
	return o.abortedTransactions
}

func (o *PartitionData) SetAbortedTransactions(val []partitiondata.AbortedTransaction) {
	o.isNil = false
	o.abortedTransactions = val
}

func (o *PartitionData) PreferredReadReplica() int32 {
	return o.preferredReadReplica
}

func (o *PartitionData) SetPreferredReadReplica(val int32) {
	o.isNil = false
	o.preferredReadReplica = val
}

func (o *PartitionData) Records() fields.RecordBatches {
	return o.records
}

func (o *PartitionData) SetRecords(val fields.RecordBatches) {
	o.isNil = false
	o.records = val
}

func (o *PartitionData) UnknownTaggedFields() []fields.RawTaggedField {
	return o.unknownTaggedFields
}

func (o *PartitionData) SetUnknownTaggedFields(val []fields.RawTaggedField) {
	o.unknownTaggedFields = val
}

func (o *PartitionData) Read(buf *bytes.Reader, version int16) error {
	o.SetDefault()

	partitionIndexField := fields.Int32{Context: partitionDataPartitionIndex}
	if err := partitionIndexField.Read(buf, version, &o.partitionIndex); err != nil {
		return errors.WrapIf(err, "couldn't set \"partitionIndex\" field")
	}

	errorCodeField := fields.Int16{Context: partitionDataErrorCode}
	if err := errorCodeField.Read(buf, version, &o.errorCode); err != nil {
		return errors.WrapIf(err, "couldn't set \"errorCode\" field")
	}

	highWatermarkField := fields.Int64{Context: partitionDataHighWatermark}
	if err := highWatermarkField.Read(buf, version, &o.highWatermark); err != nil {
		return errors.WrapIf(err, "couldn't set \"highWatermark\" field")
	}

	lastStableOffsetField := fields.Int64{Context: partitionDataLastStableOffset}
	if err := lastStableOffsetField.Read(buf, version, &o.lastStableOffset); err != nil {
		return errors.WrapIf(err, "couldn't set \"lastStableOffset\" field")
	}

	logStartOffsetField := fields.Int64{Context: partitionDataLogStartOffset}
	if err := logStartOffsetField.Read(buf, version, &o.logStartOffset); err != nil {
		return errors.WrapIf(err, "couldn't set \"logStartOffset\" field")
	}

	abortedTransactionsField := fields.ArrayOfStruct[partitiondata.AbortedTransaction, *partitiondata.AbortedTransaction]{Context: partitionDataAbortedTransactions}
	abortedTransactions, err := abortedTransactionsField.Read(buf, version)
	if err != nil {
		return errors.WrapIf(err, "couldn't set \"abortedTransactions\" field")
	}
	o.abortedTransactions = abortedTransactions

	preferredReadReplicaField := fields.Int32{Context: partitionDataPreferredReadReplica}
	if err := preferredReadReplicaField.Read(buf, version, &o.preferredReadReplica); err != nil {
		return errors.WrapIf(err, "couldn't set \"preferredReadReplica\" field")
	}

	recordsField := fields.Records{Context: partitionDataRecords}
	if err := recordsField.Read(buf, version, &o.records); err != nil {
		return errors.WrapIf(err, "couldn't set \"records\" field")
	}

	// process tagged fields

	if version < PartitionDataLowestSupportedFlexVersion() || version > PartitionDataHighestSupportedFlexVersion() {
		// tagged fields are only supported by flexible versions
		o.isNil = false
		return nil
	}

	if buf.Len() == 0 {
		o.isNil = false
		return nil
	}

	rawTaggedFields, err := fields.ReadRawTaggedFields(buf)
	if err != nil {
		return err
	}

	for i := range rawTaggedFields {
		switch rawTaggedFields[i].Tag() {
		case 0:
			if !partitionDataDivergingEpoch.IsTaggedVersion(version) {
				return errors.New(strings.Join([]string{"tagged field \"divergingEpoch\" is not supported by version", strconv.Itoa(int(version))}, " "))
			}
			if err := o.divergingEpoch.Read(bytes.NewReader(rawTaggedFields[i].Value()), version); err != nil {
				return errors.WrapIf(err, "couldn't set \"divergingEpoch\" field")
			}
			rawTaggedFields[i].Release()
		case 1:
			if !partitionDataCurrentLeader.IsTaggedVersion(version) {
				return errors.New(strings.Join([]string{"tagged field \"currentLeader\" is not supported by version", strconv.Itoa(int(version))}, " "))
			}
			if err := o.currentLeader.Read(bytes.NewReader(rawTaggedFields[i].Value()), version); err != nil {
				return errors.WrapIf(err, "couldn't set \"currentLeader\" field")
			}
			rawTaggedFields[i].Release()
		case 2:
			if !partitionDataSnapshotId.IsTaggedVersion(version) {
				return errors.New(strings.Join([]string{"tagged field \"snapshotId\" is not supported by version", strconv.Itoa(int(version))}, " "))
			}
			if err := o.snapshotId.Read(bytes.NewReader(rawTaggedFields[i].Value()), version); err != nil {
				return errors.WrapIf(err, "couldn't set \"snapshotId\" field")
			}
			rawTaggedFields[i].Release()
		default:
			o.unknownTaggedFields = append(o.unknownTaggedFields, rawTaggedFields[i])
		}
	}

	o.isNil = false
	return nil
}

func (o *PartitionData) Write(buf *typesbytes.SliceWriter, version int16) error {
	if o.IsNil() {
		return nil
	}
	if err := o.validateNonIgnorableFields(version); err != nil {
		return err
	}

	partitionIndexField := fields.Int32{Context: partitionDataPartitionIndex}
	if err := partitionIndexField.Write(buf, version, o.partitionIndex); err != nil {
		return errors.WrapIf(err, "couldn't serialize \"partitionIndex\" field")
	}
	errorCodeField := fields.Int16{Context: partitionDataErrorCode}
	if err := errorCodeField.Write(buf, version, o.errorCode); err != nil {
		return errors.WrapIf(err, "couldn't serialize \"errorCode\" field")
	}
	highWatermarkField := fields.Int64{Context: partitionDataHighWatermark}
	if err := highWatermarkField.Write(buf, version, o.highWatermark); err != nil {
		return errors.WrapIf(err, "couldn't serialize \"highWatermark\" field")
	}
	lastStableOffsetField := fields.Int64{Context: partitionDataLastStableOffset}
	if err := lastStableOffsetField.Write(buf, version, o.lastStableOffset); err != nil {
		return errors.WrapIf(err, "couldn't serialize \"lastStableOffset\" field")
	}
	logStartOffsetField := fields.Int64{Context: partitionDataLogStartOffset}
	if err := logStartOffsetField.Write(buf, version, o.logStartOffset); err != nil {
		return errors.WrapIf(err, "couldn't serialize \"logStartOffset\" field")
	}

	abortedTransactionsField := fields.ArrayOfStruct[partitiondata.AbortedTransaction, *partitiondata.AbortedTransaction]{Context: partitionDataAbortedTransactions}
	if err := abortedTransactionsField.Write(buf, version, o.abortedTransactions); err != nil {
		return errors.WrapIf(err, "couldn't serialize \"abortedTransactions\" field")
	}

	preferredReadReplicaField := fields.Int32{Context: partitionDataPreferredReadReplica}
	if err := preferredReadReplicaField.Write(buf, version, o.preferredReadReplica); err != nil {
		return errors.WrapIf(err, "couldn't serialize \"preferredReadReplica\" field")
	}
	recordsField := fields.Records{Context: partitionDataRecords}
	if err := recordsField.Write(buf, version, &o.records); err != nil {
		return errors.WrapIf(err, "couldn't serialize \"records\" field")
	}

	// serialize tagged fields
	numTaggedFields := o.getTaggedFieldsCount(version)
	if version < PartitionDataLowestSupportedFlexVersion() || version > PartitionDataHighestSupportedFlexVersion() {
		if numTaggedFields > 0 {
			return errors.New(strings.Join([]string{"tagged fields were set, but version", strconv.Itoa(int(version)), "of this message does not support them"}, " "))
		}

		return nil
	}

	rawTaggedFields := make([]fields.RawTaggedField, 0, numTaggedFields)
	rawTaggedFields = append(rawTaggedFields, o.unknownTaggedFields...)
	var taggedField fields.RawTaggedField

	divergingEpochDefaultValue := partitiondata.EpochEndOffsetDefault()
	if partitionDataDivergingEpoch.IsTaggedVersion(version) && !o.divergingEpoch.Equal(&divergingEpochDefaultValue) {
		size, err := o.divergingEpoch.SizeInBytes(version)
		if err != nil {
			return errors.WrapIf(err, "couldn't determine \"divergingEpoch\" field size in bytes")
		}
		w := typesbytes.NewSliceWriter(make([]byte, 0, size))
		if err := o.divergingEpoch.Write(&w, version); err != nil {
			return errors.WrapIf(err, "couldn't serialize \"divergingEpoch\" field")
		}
		taggedField.SetTag(0)
		taggedField.SetValue(w.Bytes())
		rawTaggedFields = append(rawTaggedFields, taggedField)
	}
	currentLeaderDefaultValue := partitiondata.LeaderIdAndEpochDefault()
	if partitionDataCurrentLeader.IsTaggedVersion(version) && !o.currentLeader.Equal(&currentLeaderDefaultValue) {
		size, err := o.currentLeader.SizeInBytes(version)
		if err != nil {
			return errors.WrapIf(err, "couldn't determine \"currentLeader\" field size in bytes")
		}
		w := typesbytes.NewSliceWriter(make([]byte, 0, size))
		if err := o.currentLeader.Write(&w, version); err != nil {
			return errors.WrapIf(err, "couldn't serialize \"currentLeader\" field")
		}
		taggedField.SetTag(1)
		taggedField.SetValue(w.Bytes())
		rawTaggedFields = append(rawTaggedFields, taggedField)
	}
	snapshotIdDefaultValue := partitiondata.SnapshotIdDefault()
	if partitionDataSnapshotId.IsTaggedVersion(version) && !o.snapshotId.Equal(&snapshotIdDefaultValue) {
		size, err := o.snapshotId.SizeInBytes(version)
		if err != nil {
			return errors.WrapIf(err, "couldn't determine \"snapshotId\" field size in bytes")
		}
		w := typesbytes.NewSliceWriter(make([]byte, 0, size))
		if err := o.snapshotId.Write(&w, version); err != nil {
			return errors.WrapIf(err, "couldn't serialize \"snapshotId\" field")
		}
		taggedField.SetTag(2)
		taggedField.SetValue(w.Bytes())
		rawTaggedFields = append(rawTaggedFields, taggedField)
	}

	if err := fields.WriteRawTaggedFields(buf, rawTaggedFields); err != nil {
		return errors.WrapIf(err, "couldn't serialize tagged fields")
	}

	return nil
}

func (o *PartitionData) String() string {
	s, err := o.MarshalJSON()
	if err != nil {
		return err.Error()
	}

	return string(s)
}

func (o *PartitionData) MarshalJSON() ([]byte, error) {
	if o == nil || o.IsNil() {
		return []byte("null"), nil
	}

	s := make([][]byte, 0, 12)
	if b, err := fields.MarshalPrimitiveTypeJSON(o.partitionIndex); err != nil {
		return nil, err
	} else {
		s = append(s, bytes.Join([][]byte{[]byte("\"partitionIndex\""), b}, []byte(": ")))
	}
	if b, err := fields.MarshalPrimitiveTypeJSON(o.errorCode); err != nil {
		return nil, err
	} else {
		s = append(s, bytes.Join([][]byte{[]byte("\"errorCode\""), b}, []byte(": ")))
	}
	if b, err := fields.MarshalPrimitiveTypeJSON(o.highWatermark); err != nil {
		return nil, err
	} else {
		s = append(s, bytes.Join([][]byte{[]byte("\"highWatermark\""), b}, []byte(": ")))
	}
	if b, err := fields.MarshalPrimitiveTypeJSON(o.lastStableOffset); err != nil {
		return nil, err
	} else {
		s = append(s, bytes.Join([][]byte{[]byte("\"lastStableOffset\""), b}, []byte(": ")))
	}
	if b, err := fields.MarshalPrimitiveTypeJSON(o.logStartOffset); err != nil {
		return nil, err
	} else {
		s = append(s, bytes.Join([][]byte{[]byte("\"logStartOffset\""), b}, []byte(": ")))
	}
	if b, err := o.divergingEpoch.MarshalJSON(); err != nil {
		return nil, err
	} else {
		s = append(s, bytes.Join([][]byte{[]byte("\"divergingEpoch\""), b}, []byte(": ")))
	}
	if b, err := o.currentLeader.MarshalJSON(); err != nil {
		return nil, err
	} else {
		s = append(s, bytes.Join([][]byte{[]byte("\"currentLeader\""), b}, []byte(": ")))
	}
	if b, err := o.snapshotId.MarshalJSON(); err != nil {
		return nil, err
	} else {
		s = append(s, bytes.Join([][]byte{[]byte("\"snapshotId\""), b}, []byte(": ")))
	}
	if b, err := fields.ArrayOfStructMarshalJSON("abortedTransactions", o.abortedTransactions); err != nil {
		return nil, err
	} else {
		s = append(s, b)
	}
	if b, err := fields.MarshalPrimitiveTypeJSON(o.preferredReadReplica); err != nil {
		return nil, err
	} else {
		s = append(s, bytes.Join([][]byte{[]byte("\"preferredReadReplica\""), b}, []byte(": ")))
	}
	if b, err := o.records.MarshalJSON(); err != nil {
		return nil, err
	} else {
		s = append(s, bytes.Join([][]byte{[]byte("\"records\""), b}, []byte(": ")))
	}

	if b, err := fields.ArrayOfStructMarshalJSON("unknownTaggedFields", o.unknownTaggedFields); err != nil {
		return nil, err
	} else {
		s = append(s, b)
	}

	var b bytes.Buffer
	if err := b.WriteByte('{'); err != nil {
		return nil, err
	}
	if _, err := b.Write(bytes.Join(s, []byte(", "))); err != nil {
		return nil, err
	}
	if err := b.WriteByte('}'); err != nil {
		return nil, err
	}

	return b.Bytes(), nil
}

func (o *PartitionData) IsNil() bool {
	return o.isNil
}

func (o *PartitionData) Clear() {
	o.Release()
	o.isNil = true

	o.divergingEpoch.Clear()
	o.currentLeader.Clear()
	o.snapshotId.Clear()
	o.abortedTransactions = nil
	o.unknownTaggedFields = nil
}

func (o *PartitionData) SetDefault() {
	for i := range o.unknownTaggedFields {
		o.unknownTaggedFields[i].Release()
	}
	o.unknownTaggedFields = nil
	o.partitionIndex = 0
	o.errorCode = 0
	o.highWatermark = 0
	o.lastStableOffset = -1
	o.logStartOffset = -1
	o.divergingEpoch.SetDefault()
	o.currentLeader.SetDefault()
	o.snapshotId.SetDefault()
	for i := range o.abortedTransactions {
		o.abortedTransactions[i].Release()
	}
	o.abortedTransactions = nil
	o.preferredReadReplica = -1
	o.records.ClearAndComplete()

	o.isNil = false
}

func (o *PartitionData) Equal(that *PartitionData) bool {
	if !fields.RawTaggedFieldsEqual(o.unknownTaggedFields, that.unknownTaggedFields) {
		return false
	}

	if o.partitionIndex != that.partitionIndex {
		return false
	}
	if o.errorCode != that.errorCode {
		return false
	}
	if o.highWatermark != that.highWatermark {
		return false
	}
	if o.lastStableOffset != that.lastStableOffset {
		return false
	}
	if o.logStartOffset != that.logStartOffset {
		return false
	}
	if !o.divergingEpoch.Equal(&that.divergingEpoch) {
		return false
	}
	if !o.currentLeader.Equal(&that.currentLeader) {
		return false
	}
	if !o.snapshotId.Equal(&that.snapshotId) {
		return false
	}
	if len(o.abortedTransactions) != len(that.abortedTransactions) {
		return false
	}
	for i := range o.abortedTransactions {
		if !o.abortedTransactions[i].Equal(&that.abortedTransactions[i]) {
			return false
		}
	}
	if o.preferredReadReplica != that.preferredReadReplica {
		return false
	}
	if !o.records.Equal(&that.records) {
		return false
	}

	return true
}

// SizeInBytes returns the size of this data structure in bytes when it's serialized
func (o *PartitionData) SizeInBytes(version int16) (int, error) {
	if o.IsNil() {
		return 0, nil
	}

	if err := o.validateNonIgnorableFields(version); err != nil {
		return 0, err
	}

	size := 0
	fieldSize := 0
	var err error

	partitionIndexField := fields.Int32{Context: partitionDataPartitionIndex}
	fieldSize, err = partitionIndexField.SizeInBytes(version, o.partitionIndex)
	if err != nil {
		return 0, errors.WrapIf(err, "couldn't compute size of \"partitionIndex\" field")
	}
	size += fieldSize

	errorCodeField := fields.Int16{Context: partitionDataErrorCode}
	fieldSize, err = errorCodeField.SizeInBytes(version, o.errorCode)
	if err != nil {
		return 0, errors.WrapIf(err, "couldn't compute size of \"errorCode\" field")
	}
	size += fieldSize

	highWatermarkField := fields.Int64{Context: partitionDataHighWatermark}
	fieldSize, err = highWatermarkField.SizeInBytes(version, o.highWatermark)
	if err != nil {
		return 0, errors.WrapIf(err, "couldn't compute size of \"highWatermark\" field")
	}
	size += fieldSize

	lastStableOffsetField := fields.Int64{Context: partitionDataLastStableOffset}
	fieldSize, err = lastStableOffsetField.SizeInBytes(version, o.lastStableOffset)
	if err != nil {
		return 0, errors.WrapIf(err, "couldn't compute size of \"lastStableOffset\" field")
	}
	size += fieldSize

	logStartOffsetField := fields.Int64{Context: partitionDataLogStartOffset}
	fieldSize, err = logStartOffsetField.SizeInBytes(version, o.logStartOffset)
	if err != nil {
		return 0, errors.WrapIf(err, "couldn't compute size of \"logStartOffset\" field")
	}
	size += fieldSize

	abortedTransactionsField := fields.ArrayOfStruct[partitiondata.AbortedTransaction, *partitiondata.AbortedTransaction]{Context: partitionDataAbortedTransactions}
	fieldSize, err = abortedTransactionsField.SizeInBytes(version, o.abortedTransactions)
	if err != nil {
		return 0, errors.WrapIf(err, "couldn't compute size of \"abortedTransactions\" field")
	}
	size += fieldSize

	preferredReadReplicaField := fields.Int32{Context: partitionDataPreferredReadReplica}
	fieldSize, err = preferredReadReplicaField.SizeInBytes(version, o.preferredReadReplica)
	if err != nil {
		return 0, errors.WrapIf(err, "couldn't compute size of \"preferredReadReplica\" field")
	}
	size += fieldSize

	recordsField := fields.Records{Context: partitionDataRecords}
	fieldSize, err = recordsField.SizeInBytes(version, &o.records)
	if err != nil {
		return 0, errors.WrapIf(err, "couldn't compute size of \"records\" field")
	}
	size += fieldSize

	// tagged fields
	numTaggedFields := int64(o.getTaggedFieldsCount(version))
	if numTaggedFields > 0xffffffff {
		return 0, errors.New(strings.Join([]string{"invalid tagged fields count:", strconv.Itoa(int(numTaggedFields))}, " "))
	}
	if version < PartitionDataLowestSupportedFlexVersion() || version > PartitionDataHighestSupportedFlexVersion() {
		if numTaggedFields > 0 {
			return 0, errors.New(strings.Join([]string{"tagged fields were set, but version", strconv.Itoa(int(version)), "of this message does not support them"}, " "))
		}

		return size, nil
	}

	taggedFieldsSize := varint.Uint32Size(uint32(numTaggedFields)) // bytes for serializing the number of tagged fields
	fieldSize = 0

	divergingEpochDefaultValue := partitiondata.EpochEndOffsetDefault()
	if partitionDataDivergingEpoch.IsTaggedVersion(version) && !o.divergingEpoch.Equal(&divergingEpochDefaultValue) {
		fieldSize, err = o.divergingEpoch.SizeInBytes(version)
		if err != nil {
			return 0, errors.WrapIf(err, "couldn't compute size of \"divergingEpoch\" field")
		}
		if int64(fieldSize) > 0xffffffff {
			return 0, errors.New(strings.Join([]string{"invalid \"divergingEpoch\" tagged field value length:", strconv.Itoa(fieldSize)}, " "))
		}
		fieldSize += varint.Uint32Size(uint32(fieldSize)) // bytes for serializing the length of the "divergingEpoch" field
		fieldSize += varint.Uint32Size(0)                 // bytes for serializing the tag of the "divergingEpoch" field
		taggedFieldsSize += fieldSize
	}
	currentLeaderDefaultValue := partitiondata.LeaderIdAndEpochDefault()
	if partitionDataCurrentLeader.IsTaggedVersion(version) && !o.currentLeader.Equal(&currentLeaderDefaultValue) {
		fieldSize, err = o.currentLeader.SizeInBytes(version)
		if err != nil {
			return 0, errors.WrapIf(err, "couldn't compute size of \"currentLeader\" field")
		}
		if int64(fieldSize) > 0xffffffff {
			return 0, errors.New(strings.Join([]string{"invalid \"currentLeader\" tagged field value length:", strconv.Itoa(fieldSize)}, " "))
		}
		fieldSize += varint.Uint32Size(uint32(fieldSize)) // bytes for serializing the length of the "currentLeader" field
		fieldSize += varint.Uint32Size(1)                 // bytes for serializing the tag of the "currentLeader" field
		taggedFieldsSize += fieldSize
	}
	snapshotIdDefaultValue := partitiondata.SnapshotIdDefault()
	if partitionDataSnapshotId.IsTaggedVersion(version) && !o.snapshotId.Equal(&snapshotIdDefaultValue) {
		fieldSize, err = o.snapshotId.SizeInBytes(version)
		if err != nil {
			return 0, errors.WrapIf(err, "couldn't compute size of \"snapshotId\" field")
		}
		if int64(fieldSize) > 0xffffffff {
			return 0, errors.New(strings.Join([]string{"invalid \"snapshotId\" tagged field value length:", strconv.Itoa(fieldSize)}, " "))
		}
		fieldSize += varint.Uint32Size(uint32(fieldSize)) // bytes for serializing the length of the "snapshotId" field
		fieldSize += varint.Uint32Size(2)                 // bytes for serializing the tag of the "snapshotId" field
		taggedFieldsSize += fieldSize
	}

	for i := range o.unknownTaggedFields {
		length := len(o.unknownTaggedFields[i].Value())
		if int64(length) > 0xffffffff {
			return 0, errors.New(strings.Join([]string{"invalid field value length:", strconv.Itoa(length), ", tag:", strconv.Itoa(int(o.unknownTaggedFields[i].Tag()))}, " "))
		}
		taggedFieldsSize += varint.Uint32Size(o.unknownTaggedFields[i].Tag()) // bytes for serializing the tag of the unknown tag
		taggedFieldsSize += varint.Uint32Size(uint32(length))                 // bytes for serializing the length of the unknown tagged field
		taggedFieldsSize += length
	}

	size += taggedFieldsSize

	return size, nil
}

// Release releases the dynamically allocated fields of this object by returning then to object pools
func (o *PartitionData) Release() {
	if o.IsNil() {
		return
	}

	for i := range o.unknownTaggedFields {
		o.unknownTaggedFields[i].Release()
	}
	o.unknownTaggedFields = nil

	o.divergingEpoch.Release()
	o.currentLeader.Release()
	o.snapshotId.Release()
	for i := range o.abortedTransactions {
		o.abortedTransactions[i].Release()
	}
	o.abortedTransactions = nil
	o.records.Release()
}

func (o *PartitionData) getTaggedFieldsCount(version int16) int {
	numTaggedFields := len(o.unknownTaggedFields)

	if partitionDataDivergingEpoch.IsTaggedVersion(version) {
		divergingEpochDefaultValue := partitiondata.EpochEndOffsetDefault()
		if !o.divergingEpoch.Equal(&divergingEpochDefaultValue) {
			numTaggedFields++
		}
	}
	if partitionDataCurrentLeader.IsTaggedVersion(version) {
		currentLeaderDefaultValue := partitiondata.LeaderIdAndEpochDefault()
		if !o.currentLeader.Equal(&currentLeaderDefaultValue) {
			numTaggedFields++
		}
	}
	if partitionDataSnapshotId.IsTaggedVersion(version) {
		snapshotIdDefaultValue := partitiondata.SnapshotIdDefault()
		if !o.snapshotId.Equal(&snapshotIdDefaultValue) {
			numTaggedFields++
		}
	}

	return numTaggedFields
}

// validateNonIgnorableFields throws an error if any non-ignorable field not supported by current version is set to
// non-default value
func (o *PartitionData) validateNonIgnorableFields(version int16) error {
	if !partitionDataDivergingEpoch.IsSupportedVersion(version) {
		divergingEpochDefaultValue := partitiondata.EpochEndOffsetDefault()
		if !o.divergingEpoch.Equal(&divergingEpochDefaultValue) {
			return errors.New(strings.Join([]string{"attempted to write non-default \"divergingEpoch\" at version", strconv.Itoa(int(version))}, " "))
		}
	}
	if !partitionDataCurrentLeader.IsSupportedVersion(version) {
		currentLeaderDefaultValue := partitiondata.LeaderIdAndEpochDefault()
		if !o.currentLeader.Equal(&currentLeaderDefaultValue) {
			return errors.New(strings.Join([]string{"attempted to write non-default \"currentLeader\" at version", strconv.Itoa(int(version))}, " "))
		}
	}
	if !partitionDataSnapshotId.IsSupportedVersion(version) {
		snapshotIdDefaultValue := partitiondata.SnapshotIdDefault()
		if !o.snapshotId.Equal(&snapshotIdDefaultValue) {
			return errors.New(strings.Join([]string{"attempted to write non-default \"snapshotId\" at version", strconv.Itoa(int(version))}, " "))
		}
	}
	if !partitionDataPreferredReadReplica.IsSupportedVersion(version) {
		if o.preferredReadReplica != -1 {
			return errors.New(strings.Join([]string{"attempted to write non-default \"preferredReadReplica\" at version", strconv.Itoa(int(version))}, " "))
		}
	}
	return nil
}

func PartitionDataLowestSupportedVersion() int16 {
	return 0
}

func PartitionDataHighestSupportedVersion() int16 {
	return 32767
}

func PartitionDataLowestSupportedFlexVersion() int16 {
	return 12
}

func PartitionDataHighestSupportedFlexVersion() int16 {
	return 32767
}

func PartitionDataDefault() PartitionData {
	var d PartitionData
	d.SetDefault()

	return d
}
