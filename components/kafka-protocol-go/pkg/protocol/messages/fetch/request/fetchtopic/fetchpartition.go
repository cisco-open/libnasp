// Code generated by kafka-protocol-go. DO NOT EDIT.

// Copyright (c) 2023 Cisco and/or its affiliates. All rights reserved.
//
//	Licensed under the Apache License, Version 2.0 (the "License");
//	you may not use this file except in compliance with the License.
//	You may obtain a copy of the License at
//
//	     https://www.apache.org/licenses/LICENSE-2.0
//
//	Unless required by applicable law or agreed to in writing, software
//	distributed under the License is distributed on an "AS IS" BASIS,
//	WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
//	See the License for the specific language governing permissions and
//	limitations under the License.
package fetchtopic

import (
	"bytes"
	"strconv"
	"strings"

	"emperror.dev/errors"
	typesbytes "github.com/cisco-open/nasp/components/kafka-protocol-go/pkg/protocol/types/bytes"
	"github.com/cisco-open/nasp/components/kafka-protocol-go/pkg/protocol/types/fields"
	"github.com/cisco-open/nasp/components/kafka-protocol-go/pkg/protocol/types/varint"
)

var fetchPartitionPartition = fields.Context{
	SpecName:                    "Partition",
	LowestSupportedVersion:      0,
	HighestSupportedVersion:     32767,
	LowestSupportedFlexVersion:  12,
	HighestSupportedFlexVersion: 32767,
}
var fetchPartitionCurrentLeaderEpoch = fields.Context{
	SpecName:                    "CurrentLeaderEpoch",
	CustomDefaultValue:          int32(-1),
	LowestSupportedVersion:      9,
	HighestSupportedVersion:     32767,
	LowestSupportedFlexVersion:  12,
	HighestSupportedFlexVersion: 32767,
}
var fetchPartitionFetchOffset = fields.Context{
	SpecName:                    "FetchOffset",
	LowestSupportedVersion:      0,
	HighestSupportedVersion:     32767,
	LowestSupportedFlexVersion:  12,
	HighestSupportedFlexVersion: 32767,
}
var fetchPartitionLastFetchedEpoch = fields.Context{
	SpecName:                    "LastFetchedEpoch",
	CustomDefaultValue:          int32(-1),
	LowestSupportedVersion:      12,
	HighestSupportedVersion:     32767,
	LowestSupportedFlexVersion:  12,
	HighestSupportedFlexVersion: 32767,
}
var fetchPartitionLogStartOffset = fields.Context{
	SpecName:                    "LogStartOffset",
	CustomDefaultValue:          int64(-1),
	LowestSupportedVersion:      5,
	HighestSupportedVersion:     32767,
	LowestSupportedFlexVersion:  12,
	HighestSupportedFlexVersion: 32767,
}
var fetchPartitionPartitionMaxBytes = fields.Context{
	SpecName:                    "PartitionMaxBytes",
	LowestSupportedVersion:      0,
	HighestSupportedVersion:     32767,
	LowestSupportedFlexVersion:  12,
	HighestSupportedFlexVersion: 32767,
}

type FetchPartition struct {
	unknownTaggedFields []fields.RawTaggedField
	fetchOffset         int64
	logStartOffset      int64
	partition           int32
	currentLeaderEpoch  int32
	lastFetchedEpoch    int32
	partitionMaxBytes   int32
	isNil               bool
}

func (o *FetchPartition) Partition() int32 {
	return o.partition
}

func (o *FetchPartition) SetPartition(val int32) {
	o.isNil = false
	o.partition = val
}

func (o *FetchPartition) CurrentLeaderEpoch() int32 {
	return o.currentLeaderEpoch
}

func (o *FetchPartition) SetCurrentLeaderEpoch(val int32) {
	o.isNil = false
	o.currentLeaderEpoch = val
}

func (o *FetchPartition) FetchOffset() int64 {
	return o.fetchOffset
}

func (o *FetchPartition) SetFetchOffset(val int64) {
	o.isNil = false
	o.fetchOffset = val
}

func (o *FetchPartition) LastFetchedEpoch() int32 {
	return o.lastFetchedEpoch
}

func (o *FetchPartition) SetLastFetchedEpoch(val int32) {
	o.isNil = false
	o.lastFetchedEpoch = val
}

func (o *FetchPartition) LogStartOffset() int64 {
	return o.logStartOffset
}

func (o *FetchPartition) SetLogStartOffset(val int64) {
	o.isNil = false
	o.logStartOffset = val
}

func (o *FetchPartition) PartitionMaxBytes() int32 {
	return o.partitionMaxBytes
}

func (o *FetchPartition) SetPartitionMaxBytes(val int32) {
	o.isNil = false
	o.partitionMaxBytes = val
}

func (o *FetchPartition) UnknownTaggedFields() []fields.RawTaggedField {
	return o.unknownTaggedFields
}

func (o *FetchPartition) SetUnknownTaggedFields(val []fields.RawTaggedField) {
	o.unknownTaggedFields = val
}

func (o *FetchPartition) Read(buf *bytes.Reader, version int16) error {
	o.SetDefault()

	partitionField := fields.Int32{Context: fetchPartitionPartition}
	if err := partitionField.Read(buf, version, &o.partition); err != nil {
		return errors.WrapIf(err, "couldn't set \"partition\" field")
	}

	currentLeaderEpochField := fields.Int32{Context: fetchPartitionCurrentLeaderEpoch}
	if err := currentLeaderEpochField.Read(buf, version, &o.currentLeaderEpoch); err != nil {
		return errors.WrapIf(err, "couldn't set \"currentLeaderEpoch\" field")
	}

	fetchOffsetField := fields.Int64{Context: fetchPartitionFetchOffset}
	if err := fetchOffsetField.Read(buf, version, &o.fetchOffset); err != nil {
		return errors.WrapIf(err, "couldn't set \"fetchOffset\" field")
	}

	lastFetchedEpochField := fields.Int32{Context: fetchPartitionLastFetchedEpoch}
	if err := lastFetchedEpochField.Read(buf, version, &o.lastFetchedEpoch); err != nil {
		return errors.WrapIf(err, "couldn't set \"lastFetchedEpoch\" field")
	}

	logStartOffsetField := fields.Int64{Context: fetchPartitionLogStartOffset}
	if err := logStartOffsetField.Read(buf, version, &o.logStartOffset); err != nil {
		return errors.WrapIf(err, "couldn't set \"logStartOffset\" field")
	}

	partitionMaxBytesField := fields.Int32{Context: fetchPartitionPartitionMaxBytes}
	if err := partitionMaxBytesField.Read(buf, version, &o.partitionMaxBytes); err != nil {
		return errors.WrapIf(err, "couldn't set \"partitionMaxBytes\" field")
	}

	// process tagged fields

	if version < FetchPartitionLowestSupportedFlexVersion() || version > FetchPartitionHighestSupportedFlexVersion() {
		// tagged fields are only supported by flexible versions
		o.isNil = false
		return nil
	}

	if buf.Len() == 0 {
		o.isNil = false
		return nil
	}

	rawTaggedFields, err := fields.ReadRawTaggedFields(buf)
	if err != nil {
		return err
	}

	o.unknownTaggedFields = rawTaggedFields

	o.isNil = false
	return nil
}

func (o *FetchPartition) Write(buf *typesbytes.SliceWriter, version int16) error {
	if o.IsNil() {
		return nil
	}
	if err := o.validateNonIgnorableFields(version); err != nil {
		return err
	}

	partitionField := fields.Int32{Context: fetchPartitionPartition}
	if err := partitionField.Write(buf, version, o.partition); err != nil {
		return errors.WrapIf(err, "couldn't serialize \"partition\" field")
	}
	currentLeaderEpochField := fields.Int32{Context: fetchPartitionCurrentLeaderEpoch}
	if err := currentLeaderEpochField.Write(buf, version, o.currentLeaderEpoch); err != nil {
		return errors.WrapIf(err, "couldn't serialize \"currentLeaderEpoch\" field")
	}
	fetchOffsetField := fields.Int64{Context: fetchPartitionFetchOffset}
	if err := fetchOffsetField.Write(buf, version, o.fetchOffset); err != nil {
		return errors.WrapIf(err, "couldn't serialize \"fetchOffset\" field")
	}
	lastFetchedEpochField := fields.Int32{Context: fetchPartitionLastFetchedEpoch}
	if err := lastFetchedEpochField.Write(buf, version, o.lastFetchedEpoch); err != nil {
		return errors.WrapIf(err, "couldn't serialize \"lastFetchedEpoch\" field")
	}
	logStartOffsetField := fields.Int64{Context: fetchPartitionLogStartOffset}
	if err := logStartOffsetField.Write(buf, version, o.logStartOffset); err != nil {
		return errors.WrapIf(err, "couldn't serialize \"logStartOffset\" field")
	}
	partitionMaxBytesField := fields.Int32{Context: fetchPartitionPartitionMaxBytes}
	if err := partitionMaxBytesField.Write(buf, version, o.partitionMaxBytes); err != nil {
		return errors.WrapIf(err, "couldn't serialize \"partitionMaxBytes\" field")
	}

	// serialize tagged fields
	numTaggedFields := o.getTaggedFieldsCount(version)
	if version < FetchPartitionLowestSupportedFlexVersion() || version > FetchPartitionHighestSupportedFlexVersion() {
		if numTaggedFields > 0 {
			return errors.New(strings.Join([]string{"tagged fields were set, but version", strconv.Itoa(int(version)), "of this message does not support them"}, " "))
		}

		return nil
	}

	rawTaggedFields := make([]fields.RawTaggedField, 0, numTaggedFields)
	rawTaggedFields = append(rawTaggedFields, o.unknownTaggedFields...)

	if err := fields.WriteRawTaggedFields(buf, rawTaggedFields); err != nil {
		return errors.WrapIf(err, "couldn't serialize tagged fields")
	}

	return nil
}

func (o *FetchPartition) String() string {
	s, err := o.MarshalJSON()
	if err != nil {
		return err.Error()
	}

	return string(s)
}

func (o *FetchPartition) MarshalJSON() ([]byte, error) {
	if o == nil || o.IsNil() {
		return []byte("null"), nil
	}

	s := make([][]byte, 0, 7)
	if b, err := fields.MarshalPrimitiveTypeJSON(o.partition); err != nil {
		return nil, err
	} else {
		s = append(s, bytes.Join([][]byte{[]byte("\"partition\""), b}, []byte(": ")))
	}
	if b, err := fields.MarshalPrimitiveTypeJSON(o.currentLeaderEpoch); err != nil {
		return nil, err
	} else {
		s = append(s, bytes.Join([][]byte{[]byte("\"currentLeaderEpoch\""), b}, []byte(": ")))
	}
	if b, err := fields.MarshalPrimitiveTypeJSON(o.fetchOffset); err != nil {
		return nil, err
	} else {
		s = append(s, bytes.Join([][]byte{[]byte("\"fetchOffset\""), b}, []byte(": ")))
	}
	if b, err := fields.MarshalPrimitiveTypeJSON(o.lastFetchedEpoch); err != nil {
		return nil, err
	} else {
		s = append(s, bytes.Join([][]byte{[]byte("\"lastFetchedEpoch\""), b}, []byte(": ")))
	}
	if b, err := fields.MarshalPrimitiveTypeJSON(o.logStartOffset); err != nil {
		return nil, err
	} else {
		s = append(s, bytes.Join([][]byte{[]byte("\"logStartOffset\""), b}, []byte(": ")))
	}
	if b, err := fields.MarshalPrimitiveTypeJSON(o.partitionMaxBytes); err != nil {
		return nil, err
	} else {
		s = append(s, bytes.Join([][]byte{[]byte("\"partitionMaxBytes\""), b}, []byte(": ")))
	}

	if b, err := fields.ArrayOfStructMarshalJSON("unknownTaggedFields", o.unknownTaggedFields); err != nil {
		return nil, err
	} else {
		s = append(s, b)
	}

	var b bytes.Buffer
	if err := b.WriteByte('{'); err != nil {
		return nil, err
	}
	if _, err := b.Write(bytes.Join(s, []byte(", "))); err != nil {
		return nil, err
	}
	if err := b.WriteByte('}'); err != nil {
		return nil, err
	}

	return b.Bytes(), nil
}

func (o *FetchPartition) IsNil() bool {
	return o.isNil
}

func (o *FetchPartition) Clear() {
	o.Release()
	o.isNil = true

	o.unknownTaggedFields = nil
}

func (o *FetchPartition) SetDefault() {
	for i := range o.unknownTaggedFields {
		o.unknownTaggedFields[i].Release()
	}
	o.unknownTaggedFields = nil
	o.partition = 0
	o.currentLeaderEpoch = -1
	o.fetchOffset = 0
	o.lastFetchedEpoch = -1
	o.logStartOffset = -1
	o.partitionMaxBytes = 0

	o.isNil = false
}

func (o *FetchPartition) Equal(that *FetchPartition) bool {
	if !fields.RawTaggedFieldsEqual(o.unknownTaggedFields, that.unknownTaggedFields) {
		return false
	}

	if o.partition != that.partition {
		return false
	}
	if o.currentLeaderEpoch != that.currentLeaderEpoch {
		return false
	}
	if o.fetchOffset != that.fetchOffset {
		return false
	}
	if o.lastFetchedEpoch != that.lastFetchedEpoch {
		return false
	}
	if o.logStartOffset != that.logStartOffset {
		return false
	}
	if o.partitionMaxBytes != that.partitionMaxBytes {
		return false
	}

	return true
}

// SizeInBytes returns the size of this data structure in bytes when it's serialized
func (o *FetchPartition) SizeInBytes(version int16) (int, error) {
	if o.IsNil() {
		return 0, nil
	}

	if err := o.validateNonIgnorableFields(version); err != nil {
		return 0, err
	}

	size := 0
	fieldSize := 0
	var err error

	partitionField := fields.Int32{Context: fetchPartitionPartition}
	fieldSize, err = partitionField.SizeInBytes(version, o.partition)
	if err != nil {
		return 0, errors.WrapIf(err, "couldn't compute size of \"partition\" field")
	}
	size += fieldSize

	currentLeaderEpochField := fields.Int32{Context: fetchPartitionCurrentLeaderEpoch}
	fieldSize, err = currentLeaderEpochField.SizeInBytes(version, o.currentLeaderEpoch)
	if err != nil {
		return 0, errors.WrapIf(err, "couldn't compute size of \"currentLeaderEpoch\" field")
	}
	size += fieldSize

	fetchOffsetField := fields.Int64{Context: fetchPartitionFetchOffset}
	fieldSize, err = fetchOffsetField.SizeInBytes(version, o.fetchOffset)
	if err != nil {
		return 0, errors.WrapIf(err, "couldn't compute size of \"fetchOffset\" field")
	}
	size += fieldSize

	lastFetchedEpochField := fields.Int32{Context: fetchPartitionLastFetchedEpoch}
	fieldSize, err = lastFetchedEpochField.SizeInBytes(version, o.lastFetchedEpoch)
	if err != nil {
		return 0, errors.WrapIf(err, "couldn't compute size of \"lastFetchedEpoch\" field")
	}
	size += fieldSize

	logStartOffsetField := fields.Int64{Context: fetchPartitionLogStartOffset}
	fieldSize, err = logStartOffsetField.SizeInBytes(version, o.logStartOffset)
	if err != nil {
		return 0, errors.WrapIf(err, "couldn't compute size of \"logStartOffset\" field")
	}
	size += fieldSize

	partitionMaxBytesField := fields.Int32{Context: fetchPartitionPartitionMaxBytes}
	fieldSize, err = partitionMaxBytesField.SizeInBytes(version, o.partitionMaxBytes)
	if err != nil {
		return 0, errors.WrapIf(err, "couldn't compute size of \"partitionMaxBytes\" field")
	}
	size += fieldSize

	// tagged fields
	numTaggedFields := int64(o.getTaggedFieldsCount(version))
	if numTaggedFields > 0xffffffff {
		return 0, errors.New(strings.Join([]string{"invalid tagged fields count:", strconv.Itoa(int(numTaggedFields))}, " "))
	}
	if version < FetchPartitionLowestSupportedFlexVersion() || version > FetchPartitionHighestSupportedFlexVersion() {
		if numTaggedFields > 0 {
			return 0, errors.New(strings.Join([]string{"tagged fields were set, but version", strconv.Itoa(int(version)), "of this message does not support them"}, " "))
		}

		return size, nil
	}

	taggedFieldsSize := varint.Uint32Size(uint32(numTaggedFields)) // bytes for serializing the number of tagged fields

	for i := range o.unknownTaggedFields {
		length := len(o.unknownTaggedFields[i].Value())
		if int64(length) > 0xffffffff {
			return 0, errors.New(strings.Join([]string{"invalid field value length:", strconv.Itoa(length), ", tag:", strconv.Itoa(int(o.unknownTaggedFields[i].Tag()))}, " "))
		}
		taggedFieldsSize += varint.Uint32Size(o.unknownTaggedFields[i].Tag()) // bytes for serializing the tag of the unknown tag
		taggedFieldsSize += varint.Uint32Size(uint32(length))                 // bytes for serializing the length of the unknown tagged field
		taggedFieldsSize += length
	}

	size += taggedFieldsSize

	return size, nil
}

// Release releases the dynamically allocated fields of this object by returning then to object pools
func (o *FetchPartition) Release() {
	if o.IsNil() {
		return
	}

	for i := range o.unknownTaggedFields {
		o.unknownTaggedFields[i].Release()
	}
	o.unknownTaggedFields = nil

}

func (o *FetchPartition) getTaggedFieldsCount(version int16) int {
	numTaggedFields := len(o.unknownTaggedFields)

	return numTaggedFields
}

// validateNonIgnorableFields throws an error if any non-ignorable field not supported by current version is set to
// non-default value
func (o *FetchPartition) validateNonIgnorableFields(version int16) error {
	if !fetchPartitionLastFetchedEpoch.IsSupportedVersion(version) {
		if o.lastFetchedEpoch != -1 {
			return errors.New(strings.Join([]string{"attempted to write non-default \"lastFetchedEpoch\" at version", strconv.Itoa(int(version))}, " "))
		}
	}
	return nil
}

func FetchPartitionLowestSupportedVersion() int16 {
	return 0
}

func FetchPartitionHighestSupportedVersion() int16 {
	return 32767
}

func FetchPartitionLowestSupportedFlexVersion() int16 {
	return 12
}

func FetchPartitionHighestSupportedFlexVersion() int16 {
	return 32767
}

func FetchPartitionDefault() FetchPartition {
	var d FetchPartition
	d.SetDefault()

	return d
}
